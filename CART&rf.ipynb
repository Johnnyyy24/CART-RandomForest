{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ulyRzwXvWRh"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from operator import itemgetter\r\n",
        "import copy\r\n",
        "import random\r\n",
        "import statistics"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8-rDbg5vXZM"
      },
      "source": [
        "columns_name = []\r\n",
        "for i in range(1,11):\r\n",
        "    columns_name.append(\"x\"+str(i))\r\n",
        "columns_name.append(\"y\")\r\n",
        "train_dat = pd.read_excel('hw6_train.xlsx',names=columns_name, header=None) \r\n",
        "test_dat = pd.read_excel('hw6_test.xlsx',names=columns_name, header=None)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def TransformToList(data): #把資料轉成 list 呈現\r\n",
        "    data_list = list()\r\n",
        "    for i in range(len(data)):\r\n",
        "        data_list.append(list(data.iloc[i]))\r\n",
        "    return data_list\r\n",
        "train_list = TransformToList(train_dat) \r\n",
        "test_list = TransformToList(test_dat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSNLHeXqwx4B"
      },
      "source": [
        "def get_thresholds(index,dataset): #dataset sent in here should be already sorted \r\n",
        "    thresholds = []\r\n",
        "    thresholds.append(dataset[0][index]-1) #first threshold\r\n",
        "    for i in range(len(dataset)):\r\n",
        "        if(i!=0): #if not the first row\r\n",
        "            prev = dataset[i-1][index]\r\n",
        "            cur = dataset[i][index]\r\n",
        "            if(prev!=cur):\r\n",
        "                thresholds.append((prev+cur)/2) #add the mean as one threshold\r\n",
        "    thresholds.append(dataset[-1][index]+1) #last threshold\r\n",
        "    return thresholds\r\n",
        "\r\n",
        "def data_split(index, value, dataset): #把資料分成左子樹，右子樹\r\n",
        "\tleft,right = list(),list()\r\n",
        "\tfor row in dataset:\r\n",
        "\t\tif(row[index] < value):\r\n",
        "\t\t\tleft.append(row)\r\n",
        "\t\telse:\r\n",
        "\t\t\tright.append(row)\r\n",
        "\treturn left, right\r\n",
        "\r\n",
        "def gini_index(groups): #return the best threshold for that index\r\n",
        "    gini = 0.0 #of the threshold\r\n",
        "    for group in groups:\r\n",
        "        if(len(group)==0): #avoid divided by zero\r\n",
        "            continue\r\n",
        "        pos_y = 0 #how many positive labels in the group\r\n",
        "        for row in group:\r\n",
        "            if(row[-1]==1):\r\n",
        "                pos_y += 1\r\n",
        "        neg_y = len(group) - pos_y\r\n",
        "        gini_index = (1 - (pos_y/len(group))**2 - (neg_y/len(group))**2) \r\n",
        "        gini += len(group) * gini_index #to weight different lengths differently\r\n",
        "    return gini\r\n",
        "\r\n",
        "def data_same(original_dataset):\r\n",
        "    dataset = copy.deepcopy(original_dataset)\r\n",
        "    for row in dataset: \r\n",
        "        row.pop() #把label拿掉\r\n",
        "    allsame = True\r\n",
        "    for i in range(len(dataset)):\r\n",
        "        if(dataset[0]!=dataset[i]):\r\n",
        "            allsame = False\r\n",
        "    return allsame"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaTFW8J5w_Xj"
      },
      "source": [
        "def get_split(dataset):\r\n",
        "    best_index, best_threshold, best_gini, best_groups = 9999, 9999, 9999, None\r\n",
        "    terminal = False #判斷是否終止\r\n",
        "    for index in range(10):\r\n",
        "        sorted_data = sorted(dataset, key=itemgetter(index))\r\n",
        "        thresholds = get_thresholds(index,sorted_data)\r\n",
        "        for threshold in thresholds:\r\n",
        "            groups = data_split(index,threshold,sorted_data)\r\n",
        "            gini = gini_index(groups)\r\n",
        "            if(gini<best_gini):\r\n",
        "                best_gini = gini\r\n",
        "                best_index,best_threshold,best_gini,best_groups = index,threshold,gini,groups\r\n",
        "    aNode = Node(best_index,best_threshold)\r\n",
        "\r\n",
        "    if(best_gini==0 or data_same(dataset)): #終止條件判斷\r\n",
        "        terminal = True\r\n",
        "    \r\n",
        "    if(terminal):\r\n",
        "        aNode.set_label(best_groups)\r\n",
        "        return aNode\r\n",
        "    else:\r\n",
        "        aNode.set_left(get_split(best_groups[0]))\r\n",
        "        aNode.set_right(get_split(best_groups[1]))\r\n",
        "        return aNode"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvW9mAQAxBwZ"
      },
      "source": [
        "class Node:\r\n",
        "    def __init__(self,index,threshold):\r\n",
        "        self.left = None \r\n",
        "        self.right = None\r\n",
        "        self.index = index\r\n",
        "        self.label_l = 0\r\n",
        "        self.label_r = 0\r\n",
        "        self.threshold = threshold\r\n",
        "    def set_left(self,aNode):\r\n",
        "        self.left = aNode\r\n",
        "    def set_right(self,aNode):\r\n",
        "        self.right = aNode\r\n",
        "    def set_label(self,best_groups): \r\n",
        "        if(self.left == None and self.right == None):#沒有子樹的代表是最下方的節點，標示出他們的label\r\n",
        "            l_sum,r_sum = 0,0\r\n",
        "            \r\n",
        "            for row in best_groups[0]: #左子樹\r\n",
        "                l_sum += row[-1]\r\n",
        "            if(l_sum>0): #如果+1比-1還要多的話，標示為+1(投票機制)\r\n",
        "                self.label_l = 1\r\n",
        "            else:\r\n",
        "                self.label_l = -1\r\n",
        "                \r\n",
        "            for row in best_groups[1]: #右\r\n",
        "                r_sum += row[-1]\r\n",
        "            if(r_sum>0): #如果+1比-1還要多的話，標示為+1(投票機制)\r\n",
        "                self.label_r = 1\r\n",
        "            else:\r\n",
        "                self.label_r = -1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uawl34r3xEKw"
      },
      "source": [
        "def prediction(dataset,aNode):\r\n",
        "    index, threshold = aNode.index, aNode.threshold\r\n",
        "    #先依index排序，再split成兩組\r\n",
        "    sorted_data = sorted(dataset, key=itemgetter(index))\r\n",
        "    groups = data_split(index,threshold,dataset)\r\n",
        "    err = 0\r\n",
        "    results = []\r\n",
        "    if(aNode.left == None): # it doesn't have any child node, we should do the classification\r\n",
        "        #左節點\r\n",
        "        for row in groups[0]:\r\n",
        "            results.append((row,aNode.label_l))\r\n",
        "            if(row[-1]!=aNode.label_l):\r\n",
        "                err += 1\r\n",
        "        #右節點\r\n",
        "        for row in groups[1]:\r\n",
        "            results.append((row,aNode.label_r))\r\n",
        "            if(row[-1]!=aNode.label_r):\r\n",
        "                err += 1\r\n",
        "    \r\n",
        "        return err,results\r\n",
        "\r\n",
        "    else: # the node has its child nodes, keep traversing\r\n",
        "        err_l,results_l = prediction(groups[0],aNode.left)\r\n",
        "        err_r,results_r = prediction(groups[1],aNode.right)\r\n",
        "        err += err_l+err_r #add the classification error of two child nodes to err\r\n",
        "\r\n",
        "        for element in results_l:\r\n",
        "            results.append(element)\r\n",
        "        for element in results_r:\r\n",
        "            results.append(element)\r\n",
        "        return err,results\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByyZvPGWxGwE"
      },
      "source": [
        "def Bagging(fraction,dataset):\r\n",
        "    bagging_len = int(fraction*len(dataset))\r\n",
        "    bagging_data = []\r\n",
        "    index_list = random.choices(range(0,len(dataset)),k=bagging_len)\r\n",
        "    for index in index_list:\r\n",
        "      bagging_data.append(dataset[index])\r\n",
        "    return bagging_data\r\n",
        "\r\n",
        "def RandomForest(training_data,testing_data,NumberofTrees): #隨機張森林\r\n",
        "    errs = []\r\n",
        "    results = {}\r\n",
        "    for i in range(NumberofTrees): #the bagging process\r\n",
        "        temp_train = Bagging(0.5,training_data)\r\n",
        "        aNode = get_split(temp_train)\r\n",
        "        err,result = prediction(testing_data,aNode)\r\n",
        "        errs.append(err)\r\n",
        "        for row in result:\r\n",
        "            if(tuple(row[0]) not in results):\r\n",
        "                results[tuple(row[0])] = row[1]\r\n",
        "            else:\r\n",
        "                results[tuple(row[0])] += row[1]\r\n",
        "    return statistics.mean(errs)/len(testing_data), results"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrQv5JzWxI9B"
      },
      "source": [
        "def sign(x):\r\n",
        "    if(x>0):\r\n",
        "        return 1\r\n",
        "    else:\r\n",
        "        return -1\r\n",
        "def ErrorFunction(results):\r\n",
        "    error = 0\r\n",
        "    for key in results:\r\n",
        "        if(sign(results[key])!=key[-1]):\r\n",
        "            error += 1\r\n",
        "    return error/len(results)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KL9r6xIpuZwM",
        "outputId": "5b1d13ce-7a10-43dd-d347-5204a075df71"
      },
      "source": [
        "# ein of CART\r\n",
        "aNode = get_split(train_list)\r\n",
        "err,result = prediction(train_list,aNode)\r\n",
        "print(err/len(train_list))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qQdBs6reun0",
        "outputId": "d53cfdd2-6252-4f38-9ed4-5a9fd1ac904e"
      },
      "source": [
        "# eout of CART\r\n",
        "aNode = get_split(train_list)\r\n",
        "err,result = prediction(test_list,aNode)\r\n",
        "print(err/len(train_list))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.166\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JANoVwuixK0q",
        "outputId": "cf4c3b96-e18d-42a1-c089-175e10629893"
      },
      "source": [
        "# ein of Random Forest\r\n",
        "err,results = RandomForest(train_list,train_list,200)\r\n",
        "print(ErrorFunction(results))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gt9PXyX_LCM",
        "outputId": "f4755840-b3ee-45c8-a333-410f8dd0a2c5"
      },
      "source": [
        "# # eout of Random Forest\r\n",
        "err,results = RandomForest(train_list,test_list,200)\r\n",
        "print(ErrorFunction(results))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.152\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-0c5K2XK4JL"
      },
      "source": [
        "def RandomForest_oob(training_data,NumberofTrees): \r\n",
        "    errs = []\r\n",
        "    results = {}\r\n",
        "    for i in range(NumberofTrees): #the bagging process\r\n",
        "        oob_data = []\r\n",
        "        temp_train = Bagging(0.5,training_data)\r\n",
        "        aNode = get_split(temp_train)\r\n",
        "        #find oob data\r\n",
        "        for row in training_data:\r\n",
        "          if(row not in temp_train):\r\n",
        "            oob_data.append(row)\r\n",
        "        err,result = prediction(oob_data,aNode)\r\n",
        "        errs.append(err)\r\n",
        "        for row in result:\r\n",
        "            if(tuple(row[0]) not in results):\r\n",
        "                results[tuple(row[0])] = row[1]\r\n",
        "            else:\r\n",
        "                results[tuple(row[0])] += row[1]\r\n",
        "    return statistics.mean(errs)/len(training_data),results"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2wcL91PSJz1",
        "outputId": "d81e1f8c-e76d-45ab-d7ec-8a9c0a2b5a75"
      },
      "source": [
        "# eoob of Random Forest\r\n",
        "err_oob,results_oob = RandomForest_oob(train_list,200)\r\n",
        "ErrorFunction(results_oob)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.069"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}